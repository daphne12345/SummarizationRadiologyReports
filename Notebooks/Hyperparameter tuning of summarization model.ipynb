{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJz8IHBJXEgW"
   },
   "source": [
    "# Hyperparameter tuning for summarization model (Encoder-Decoder with attention)\n",
    "Authors: Elisa Nguyen and Daphne Theodorakopoulos\n",
    "\n",
    "modified version based on Tutorial from https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3743,
     "status": "ok",
     "timestamp": 1592495938221,
     "user": {
      "displayName": "Thi Que-Lam Elisa Nguyen",
      "photoUrl": "",
      "userId": "14516834551380015257"
     },
     "user_tz": -120
    },
    "id": "wzSK7zj_dmvG",
    "outputId": "3d1f3e2e-760b-429f-f1fa-a81bf7a0e405"
   },
   "outputs": [],
   "source": [
    "!pip install py-rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3580,
     "status": "ok",
     "timestamp": 1592495938560,
     "user": {
      "displayName": "Thi Que-Lam Elisa Nguyen",
      "photoUrl": "",
      "userId": "14516834551380015257"
     },
     "user_tz": -120
    },
    "id": "y_DchlkUcCoO",
    "outputId": "d576a079-8c14-47be-9c89-41cb208b1566"
   },
   "outputs": [],
   "source": [
    "import rouge\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "pd.set_option(\"display.max_colwidth\", 200)          \n",
    "from tensorflow.keras.layers import Layer, Input, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, LSTM\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.engine import base_layer_v1\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops, math_ops\n",
    "import sys\n",
    "from AttentionLayer import AttentionLayer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tensorflow.python.ops import array_ops\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6BEp1cGXShD"
   },
   "source": [
    "## 2. Import data\n",
    "\n",
    "- load test, train, val\n",
    "- tokenize and convert findings and conclusions to numerical sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kd3_FSiHccVS"
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_excel('x_train.xlsx')\n",
    "y_train = pd.read_excel('y_train.xlsx')\n",
    "x_val = pd.read_excel('x_val.xlsx')\n",
    "y_val = pd.read_excel('y_val.xlsx')\n",
    "x_test = pd.read_excel('x_test.xlsx')\n",
    "y_test = pd.read_excel('y_test.xlsx')\n",
    "\n",
    "max_len_text = 100 \n",
    "max_len_summary = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uoh9PH6jdBNS"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "x_tokenizer.fit_on_texts(list(x_train['cleaned_text']))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_train['text_sequence'] = x_tokenizer.texts_to_sequences(x_train['cleaned_text'])\n",
    "x_val['text_sequence'] = x_tokenizer.texts_to_sequences(x_val['cleaned_text'])\n",
    "x_test['text_sequence'] = x_tokenizer.texts_to_sequences(x_test['cleaned_text'])\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_train['text_sequence'] = x_train['text_sequence'].apply(lambda x: pad_sequences([x], maxlen= max_len_text, padding='post')[0]) \n",
    "x_val['text_sequence'] = x_val['text_sequence'].apply(lambda x: pad_sequences([x], maxlen= max_len_text, padding='post')[0])\n",
    "x_test['text_sequence'] = x_test['text_sequence'].apply(lambda x: pad_sequences([x], maxlen= max_len_text, padding='post')[0])\n",
    "\n",
    "x_voc_size = len(x_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8F9PKWnLdDOL"
   },
   "outputs": [],
   "source": [
    "#preparing a tokenizer for summary on training data \n",
    "y_tokenizer = Tokenizer(filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "y_tokenizer.fit_on_texts(list(y_train['cleaned_summary']))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_train['text_sequence'] = y_tokenizer.texts_to_sequences(y_train['cleaned_summary']) \n",
    "y_val['text_sequence']= y_tokenizer.texts_to_sequences(y_val['cleaned_summary']) \n",
    "y_test['text_sequence']= y_tokenizer.texts_to_sequences(y_test['cleaned_summary']) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_train['text_sequence'] = y_train['text_sequence'].apply(lambda x: pad_sequences([x], maxlen= max_len_summary, padding='post')[0])\n",
    "y_val['text_sequence']= y_val['text_sequence'].apply(lambda x: pad_sequences([x], maxlen= max_len_summary, padding='post')[0])\n",
    "y_test['text_sequence'] = y_test['text_sequence'].apply(lambda x: pad_sequences([x], maxlen= max_len_summary, padding='post')[0])\n",
    "\n",
    "y_voc_size  =len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ve3iIy6WXUJX"
   },
   "source": [
    "## 3. Set up model functions\n",
    "\n",
    "- Model definition\n",
    "- Model inference\n",
    "- Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Op2WvF69dFeH"
   },
   "outputs": [],
   "source": [
    "def define_model(latent_dim):\n",
    "  \"\"\"\n",
    "  Function to define the Encoder-Decoder model with attention\n",
    "  :param latent_dim: int, number of hidden units per layer\n",
    "  :returns model with decoder layers, attention layer, encoder input & output & states, decoder input\n",
    "  \"\"\"\n",
    "  with tf.device('/device:GPU:0'):  \n",
    "    K.clear_session() \n",
    "    latent_dim = latent_dim \n",
    "\n",
    "    # Encoder \n",
    "    encoder_inputs = Input(shape=(max_len_text,)) \n",
    "    enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "    #LSTM 1 \n",
    "    encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "    #LSTM 2 \n",
    "    encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "    #LSTM 3 \n",
    "    encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "    encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "    # Set up the decoder. \n",
    "    decoder_inputs = Input(shape=(None,)) \n",
    "    dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "    dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "    #LSTM using encoder_states as initial state\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "    decoder_outputs1,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "    #Attention Layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer') \n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs1]) \n",
    "\n",
    "    # Concat attention output and decoder LSTM output \n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs1, attn_out])\n",
    "\n",
    "    #Dense layer\n",
    "    decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "    decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "    # Define the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "    model.summary()\n",
    "    return model, encoder_inputs, encoder_outputs, state_h, state_c, decoder_inputs, dec_emb_layer, decoder_lstm, attn_layer, decoder_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGx4yyQEf5Nu"
   },
   "outputs": [],
   "source": [
    "def model_inference(latent_dim, encoder_inputs, encoder_outputs, state_h, state_c, decoder_inputs, dec_emb_layer, decoder_lstm, attn_layer, decoder_dense):\n",
    "  \"\"\"\n",
    "  Function to do model inference to freeze the trained model and use it\n",
    "  :param latent_dim: int, number of hidden units in each layer\n",
    "  :param encoder_inputs: Input object for encoder\n",
    "  :param encoder_outputs: tensor, representing context vector\n",
    "  :param state_h: tensor, hidden state of the last encoder unit\n",
    "  :param state_c: tensor, cell state of the last encoder unit\n",
    "  :param decoder_inputs: Input object for decoder\n",
    "  :param dec_emb_layer: Embedding layer of the decoder\n",
    "  :param decoder_lstm: LSTM layer of the decoder\n",
    "  :param attn_layer: Attention layer of the decoder\n",
    "  :param decoder_dense: Dense layer of the decoder\n",
    "  :returns inferred encoder model, inferred decoder model\n",
    "  \"\"\"\n",
    "  with tf.device('/device:GPU:0'):  \n",
    "    # encoder inference\n",
    "    encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "    # decoder inference\n",
    "    # Below tensors will hold the states of the previous time step\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
    "\n",
    "    # Get the embeddings of the decoder sequence\n",
    "    dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "    # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "    decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "    #attention inference\n",
    "    attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "    # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "    decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "    # Final decoder model\n",
    "    decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c], [decoder_outputs2] + [state_h2, state_c2])\n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abLr_zbAgP0-"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model):\n",
    "  \"\"\"\n",
    "  Function to decode an input sequence, so to generate a conclusion to a finding\n",
    "  :param input_seq: sequence of ints, numerical representation of preprocessed findings\n",
    "  :param encoder_model: inferred encoder model\n",
    "  :param decoder_model: inferred decoder model\n",
    "  :returns decoded sequence as text (string)\n",
    "  \"\"\"\n",
    "  with tf.device('/device:GPU:0'):\n",
    "      reverse_target_word_index=y_tokenizer.index_word \n",
    "      reverse_source_word_index=x_tokenizer.index_word \n",
    "      target_word_index=y_tokenizer.word_index\n",
    "      # Encode the input as state vectors.\n",
    "      e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "      # Generate empty target sequence of length 1.\n",
    "      target_seq = np.zeros((1,1))\n",
    "\n",
    "      # Chose the 'start' word as the first word of the target sequence\n",
    "      target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "      stop_condition = False\n",
    "      decoded_sentence = ''\n",
    "      i=0\n",
    "      while not stop_condition:\n",
    "          output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "          # Sample a token\n",
    "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "          if sampled_token_index == 0:\n",
    "            sampled_token='end'\n",
    "            stop_condition = True\n",
    "          else:\n",
    "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "          if(sampled_token!='end'):\n",
    "              decoded_sentence += ' '+sampled_token\n",
    "\n",
    "              # Exit condition: either hit max length or find stop word.\n",
    "              if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "                  stop_condition = True\n",
    "\n",
    "          # Update the target sequence (of length 1).\n",
    "          target_seq = np.zeros((1,1))\n",
    "          target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "          # Update internal states\n",
    "          e_h, e_c = h, c\n",
    "          i += 1\n",
    "          if i == (max_len_text +1):\n",
    "            stop_condition=True\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Y92x3kugjh2"
   },
   "outputs": [],
   "source": [
    "evaluator = rouge.Rouge(metrics=['rouge-n', 'rouge-l'],\n",
    "                           max_n=2,\n",
    "                           limit_length=False,\n",
    "                           #length_limit=100,\n",
    "                           #length_limit_type='words',\n",
    "                           #apply_avg=apply_avg,\n",
    "                          # apply_best=apply_best,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           #weight_factor=1.2,\n",
    "                           stemming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHpUEykxxTI6"
   },
   "outputs": [],
   "source": [
    "def birads_score(row):\n",
    "  pre = ['birads classificatie', 'birads', 'birads-classificatie', 'birads calcificatie']\n",
    "  sec = [' rechts', ' links', ' beiderzijds', ' beide','',' ',':',' code','-code', ' categorie', ' echografisch']\n",
    "  mid = ['','-',' ','- ', ' echografisch ', ' rechts ', ' links ', ' beiderzijds ', ' thans ']\n",
    "  dic = {0:['0'],1:['1','i', 'een'], 2:['l2','2','ii', 'twee'], 3:['3','iii', 'drie'], \n",
    "         4:['4','iv', 'vier'], 5:['5', 'vijf','v'], 6:['6','vi', 'zes']}\n",
    "  for i in range(6,-1,-1): \n",
    "    for p in pre: \n",
    "      for s in sec:\n",
    "        for m in mid:\n",
    "          for val in dic[i]:\n",
    "            if (p +s+ m+ val) in row:\n",
    "              return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ssomE9XgX2IH"
   },
   "source": [
    "## 3. Hyperparameter tuning\n",
    "\n",
    "- for each hyperparameter combination of Batch sizes 64, 128, 256, 512 and latent dimensions 60, 80, 100, 120\n",
    "- train model on training set, with early stopping measured on loss on validation set\n",
    "- use trained model to generate conclusions for validation set\n",
    "- evaluate using ROUGE and accuracy\n",
    "- write all results to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "id": "yNj0lk2tfuXo",
    "outputId": "25173f9f-7cf9-490c-b918-2ad510a3d6cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 80)      1051360     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100, 80), (N 51520       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 100, 80), (N 51520       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 80)     422320      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 100, 80), (N 51520       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 80), ( 51520       embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 80), ( 12880       lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 160)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 5279)   849919      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,542,559\n",
      "Trainable params: 2,542,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      " 72/513 [===>..........................] - ETA: 7:48 - loss: 3.2977"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "  batch_sizes = [64, 128, 256, 512]\n",
    "  latent_dims = [60, 80, 100, 120]\n",
    "  df_result = pd.DataFrame(columns=['findings', 'original', 'score', 'predicted', 'birads_predicted', 'rouge', 'birads_accuracy', 'epoch', 'val_loss'])\n",
    "  df_result['findings']= x_val['cleaned_text']\n",
    "  df_result['original'] = y_val['cleaned_summary']\n",
    "  df_result['score'] = x_val['score']\n",
    "  x_val_reshaped = [x_val['text_sequence'][i].reshape(1,max_len_text) for i in range(len(x_val))]\n",
    "\n",
    "  for batch_size in batch_sizes:\n",
    "    for latent_dim in latent_dims:\n",
    "      #define model\n",
    "      model, encoder_inputs, encoder_outputs, state_h, state_c, decoder_inputs, dec_emb_layer, decoder_lstm, attn_layer, decoder_dense = define_model(latent_dim)\n",
    "      \n",
    "      #compile and train model\n",
    "      model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "      es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, restore_best_weights=True, patience=20)\n",
    "      history=model.fit([np.array(list(x_train['text_sequence'])), np.array(list(y_train['text_sequence']))[:,:-1]], np.array(list(y_train['text_sequence'])).reshape(np.array(list(y_train['text_sequence'])).shape[0],np.array(list(y_train['text_sequence'])).shape[1], 1)[:,1:] ,epochs=100,callbacks=[es],batch_size=batch_size, validation_data=([np.array(list(x_val['text_sequence'])),np.array(list(y_val['text_sequence']))[:,:-1]], np.array(list(y_val['text_sequence'])).reshape(np.array(list(y_val['text_sequence'])).shape[0],np.array(list(y_val['text_sequence'])).shape[1], 1)[:,1:]))\n",
    "      model.save_weights('path' + str(latent_dim) + 'bs' + str(batch_size))\n",
    "      \n",
    "      #decode\n",
    "      encoder_model, decoder_model = model_inference(latent_dim, encoder_inputs, encoder_outputs, state_h, state_c, decoder_inputs, dec_emb_layer, decoder_lstm, attn_layer, decoder_dense)\n",
    "      df_result['predicted'] = pd.Series(x_val_reshaped).apply(lambda x: decode_sequence([x], encoder_model=encoder_model, decoder_model=decoder_model))\n",
    "      df_result['birads_predicted'] = df_result['predicted'].apply(birads_score)\n",
    "      \n",
    "      #evaluate\n",
    "      all_hypothesis = list(df_result['predicted'])\n",
    "      all_references = list(df_result['original'])\n",
    "      scores = evaluator.get_scores(all_hypothesis, all_references)\n",
    "      df_result.loc[0, 'rouge'] = scores\n",
    "      df_result.loc[0, 'birads_accuracy'] = df_result[df_result['score']==df_result['birads_predicted']].shape[0]/df_result.shape[0]\n",
    "      df_result.loc[0, 'epoch'] = np.array(history.history['val_loss']).argmin()\n",
    "      df_result.loc[0, 'val_loss'] = history.history['val_loss'][np.array(history.history['val_loss']).argmin()]\n",
    "\n",
    "      #save results\n",
    "      df_result.to_excel('path/result_encoder_decoder_attention_dim' + str(latent_dim) + 'bs' + str(batch_size) + '.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1592387321436,
     "user": {
      "displayName": "Thi Que-Lam Elisa Nguyen",
      "photoUrl": "",
      "userId": "14516834551380015257"
     },
     "user_tz": -120
    },
    "id": "IrWua9Iqf1Jp",
    "outputId": "9f34e6ff-489e-4d63-ae9f-ad2999e760aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhP7CFuyzOXW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter tuning of summarization model",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
